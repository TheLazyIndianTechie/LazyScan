{
  "master": {
    "tasks": [
      {
        "id": 21,
        "title": "Implement asyncio-based scanning engine upgrade",
        "description": "Refactor the core scanning engine to support fully asynchronous, non-blocking directory traversal and progress reporting per v0.6.0 requirements.",
        "details": "• Research current best practices for async filesystem traversal in Python 3.11, prioritizing stdlib asyncio with selective use of asyncio.to_thread for blocking os.stat/os.scandir calls to retain cross-platform compatibility.\n• Introduce an async entrypoint scan_directory_async(...) that wraps the existing synchronous logic, emitting structured ScanResult objects while preserving backward-compatible sync wrappers.\n• Implement an asyncio.Queue-based producer/consumer pipeline to stream size data to progress callbacks without blocking the UI loop.\n• Pseudo-code:\n  async def scan_directory_async(...):\n      result = ScanResult()\n      queue = asyncio.Queue()\n      producer = asyncio.create_task(_walk_tree(path, queue, ...))\n      consumer = asyncio.create_task(_consume(queue, progress_callback, result))\n      await asyncio.gather(producer, consumer)\n      return result\n• Update the terminal progress renderer to schedule refreshes with asyncio.create_task and asyncio.sleep(0.1) for ≤100 ms responsiveness.\n• Ensure compatibility with plugin hooks by exposing awaitable scanning primitives and adding type hints, targeting mypy strict by v1.0.",
        "testStrategy": "• Add pytest-asyncio tests comparing async and legacy sync results on synthetic directory fixtures.\n• Use Hypothesis to fuzz directory structures and verify deterministic aggregation.\n• Add performance regression tests leveraging pytest-benchmark to confirm <5% overhead vs. sync mode on SSD-based fixtures.\n• Create integration tests that drive the async progress reporter and assert UI updates within the 100 ms SLA.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Research asyncio filesystem traversal patterns",
            "description": "Investigate Python 3.11 best practices for asynchronous directory traversal and blocking call handling to inform the refactor.",
            "dependencies": [],
            "details": "Survey official docs, asyncio expert discussions, and reputable blog posts on using asyncio with os.scandir/stat, including when to employ asyncio.to_thread and platform-specific caveats. Summarize findings and recommended patterns for cross-platform compatibility.\n<info added on 2025-10-04T09:51:29.392Z>\nResearch summary: For Python 3.11 async filesystem traversal, the core strategy is to wrap blocking os.scandir and os.stat in asyncio.to_thread while maintaining asynchronous coordination for queues, task orchestration, and progress updates. Best practices include leveraging DirEntry.stat caching, using asyncio.Queue to provide producer-consumer backpressure, employing asyncio.TaskGroup for concurrent directory expansion, and applying semaphore limits tuned to CPU capacity. Cross-platform guidance covers using pathlib.Path for assembly while supplying str to os.scandir, handling Windows permission and UNC path edge cases, normalizing casing on Windows when required, and tracking visited inodes on POSIX to break symlink cycles. Performance optimizations recommend metadata caching, batching work per directory to reduce thread switches, capping threadpool size to min(32, os.cpu_count() + 4), and relying on queue backpressure instead of asyncio.sleep(0). Implementation recommendations specify designing scan_directory_async around asyncio.to_thread adapters, adding structured permission error handling, writing pytest-asyncio suites with mocked os.scandir, and benchmarking against the synchronous walker to stay within a five percent overhead budget.\n</info added on 2025-10-04T09:51:29.392Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Design scan_directory_async API and data flow",
            "description": "Define the async scanning entrypoint, result types, and integration strategy with existing synchronous logic.",
            "dependencies": [
              "21.1"
            ],
            "details": "Draft function signatures, structured ScanResult schema updates, and lifecycle of async tasks. Document how legacy sync wrappers will call the async implementation and how progress callbacks receive structured updates.\n<info added on 2025-10-04T09:51:54.080Z>\nFinalized design establishes scan_directory_async(Path, follow_symlinks=False, semaphore=None, progress_callback=None) returning the typed ScanResult dataclass, enabling optional external concurrency control and structured progress callbacks. The async workflow creates an asyncio.Queue at entry, launches a producer via _walk_tree_async using asyncio.to_thread(os.scandir) with DirEntry caching, and a consumer through _aggregate_results_async that aggregates queue items and dispatches progress updates, both supervised by an asyncio.TaskGroup for coordinated cancellation. ScanResult now records total_size, file_count, dir_count, files, errors, scan_duration, and metadata. Legacy scan_directory_sync delegates to asyncio.run(scan_directory_async), async plugins call awaitable_scan_directory, and automatic event loop detection preserves backward compatibility while maintaining mypy strict type coverage. Performance considerations include cached DirEntry.stat invocations, semaphore-governed threadpool limits, queue backpressure, and structured error handling that differentiates recoverable versus fatal conditions.\n</info added on 2025-10-04T09:51:54.080Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement asyncio producer-consumer pipeline",
            "description": "Build the async traversal and progress streaming pipeline using asyncio.Queue and cooperative task orchestration.",
            "dependencies": [
              "21.2"
            ],
            "details": "Develop _walk_tree producer leveraging asyncio.to_thread where needed, consumer aggregation for ScanResult, robust cancellation/error handling, and ensure queue backpressure preserves responsiveness. Provide inline documentation and tracing hooks.\n<info added on 2025-10-04T09:53:08.269Z>\nImplemented strict-typed ScanResult dataclass capturing totals, file listings, errors, duration, and metadata. Added scan_directory_async orchestrating producer-consumer flow via asyncio.TaskGroup and bounded asyncio.Queue with backpressure-aware error handling. Delivered _walk_tree_async producer using asyncio.to_thread(os.scandir), DirEntry stat caching, and semaphore-governed concurrency to enqueue directories and file payloads. Added _aggregate_results_async consumer updating ScanResult, dispatching progress callbacks, handling error tuples, and preserving responsiveness. Introduced _list_dir_entries helper for thread-pooled directory enumeration. Tuned performance through metadata caching, semaphore sizing, queue bounds, and batch processing, with structured recoverable versus fatal error reporting, permission tolerance, and comprehensive logging.\n</info added on 2025-10-04T09:53:08.269Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Refactor progress renderer for async scheduling",
            "description": "Update the terminal progress renderer to integrate with the async event loop without blocking UI responsiveness.",
            "dependencies": [
              "21.3"
            ],
            "details": "Replace blocking refresh logic with asyncio.create_task scheduling, incorporate asyncio.sleep(0.1) pacing, and guarantee thread-safe updates for alternate frontends. Verify compatibility with Rich-based UI components.\n<info added on 2025-10-04T10:07:17.454Z>\nfrontend-dev agent assigned to refactor ProgressDisplay for asyncio.create_task scheduling with 0.1s pacing; backend-dev agent to handle asyncio integration, thread-safe alternate frontend updates, and Rich compatibility; qa-testing agent to verify thread safety, ≤100 ms responsiveness, and async pipeline compatibility. Frontend-dev implementation initiated focusing on the ProgressDisplay refactor.\n</info added on 2025-10-04T10:07:17.454Z>\n<info added on 2025-10-04T10:08:57.068Z>\nFrontend-dev agent reports ProgressDisplay refactored to use asyncio.create_task scheduling with 0.1s pacing, added batching to prevent UI flooding, replaced blocking refresh with async scheduling, and implemented async cleanup and cancellation handling; backend-dev agent now verifying asyncio integration and thread safety; qa-testing agent to validate responsiveness and compatibility.\n</info added on 2025-10-04T10:08:57.068Z>\n<info added on 2025-10-04T10:10:03.048Z>\nFrontend-dev agent completed ProgressDisplay refactor with asyncio.create_task scheduling and 0.1s pacing; backend-dev agent now verifying asyncio integration, thread-safe alternate frontend updates, and ensuring the event loop remains non-blocking; qa-testing agent queued to validate ≤100 ms responsiveness SLA and async pipeline compatibility.\n</info added on 2025-10-04T10:10:03.048Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Maintain backward-compatible synchronous wrappers",
            "description": "Adapt existing synchronous scanning interfaces to delegate to the new async implementation while preserving API contracts.",
            "dependencies": [
              "21.2",
              "21.3"
            ],
            "details": "Refactor sync entrypoints to run scan_directory_async via asyncio.run or loop management utilities, handle nested event loop scenarios, and update documentation/examples to clarify usage.\n<info added on 2025-10-04T10:12:00.003Z>\nImplement scan_directory_sync delegation to scan_directory_async using a safe run_sync helper that respects existing event loops, preserves legacy return types and exception behavior, and add regression coverage ensuring synchronous callers receive unchanged ScanResult payloads.\n</info added on 2025-10-04T10:12:00.003Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Align plugin hooks and typing for mypy strict",
            "description": "Expose awaitable primitives to plugins and add type annotations meeting mypy strict targets.",
            "dependencies": [
              "21.3",
              "21.5"
            ],
            "details": "Review plugin extension points, adjust signatures to return Awaitable types, introduce Protocols/TypedDicts as needed, and ensure mypy --strict passes with the new async constructs.\n<info added on 2025-10-04T10:16:25.107Z>\nRefactored the PluginInterface protocol and BasePlugin abstract class to expose async scan_async and clean_async hooks, updated UnityPlugin, ChromePlugin, UnrealPlugin, VSCodePlugin, and FirefoxPlugin implementations to honor the new signatures while keeping synchronous fallbacks, and confirmed mypy --strict compliance for the plugin package.\n</info added on 2025-10-04T10:16:25.107Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Develop benchmarking and property-based test suite",
            "description": "Validate async vs sync behavior through targeted benchmarks and hypothesis-driven tests.",
            "dependencies": [
              "21.3",
              "21.4",
              "21.5",
              "21.6"
            ],
            "details": "Implement pytest-asyncio parity tests against synthetic fixtures, Hypothesis-based directory fuzzing, and pytest-benchmark scenarios confirming <5% overhead. Automate comparisons against legacy sync results.\n<info added on 2025-10-04T10:17:15.252Z>\nAdded test_scan_benchmark.py covering async vs sync parity benchmarks, Hypothesis-driven directory fuzzing, concurrency scaling, error handling, and cancellation scenarios. Benchmarks confirm the asyncio engine stays within 5% of the synchronous baseline while maintaining correctness across synthetic fixtures.\n</info added on 2025-10-04T10:17:15.252Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-04T09:50:06.227Z"
      },
      {
        "id": 22,
        "title": "Enhance CLI with JSON output and advanced filtering",
        "description": "Extend the CLI to support --json output, advanced filters (--exclude, --min-size), and improved help text while maintaining cyberpunk UX.",
        "details": "• Adopt Typer 0.12.3 for CLI command definitions and ensure compatibility with existing Rich 13.7.0 styling helpers.\n• Implement a serialization layer using orjson>=3.9.15 to emit ScanResult and cleanup summaries with stable schemas.\n• Add click-option style validators for --exclude (glob), --min-size (human-readable strings via humanfriendly>=10.0), and top-N logic.\n• Provide dual rendering paths: JSON mode bypasses Rich tables and writes to stdout with ascii=False, while default mode keeps themed output.\n• Update help/usage strings to document new options and include examples in README/--help.\n• Pseudo-code:\n  @app.command()\n  def scan(..., json: bool = False, exclude: List[str] = typer.Option(...)):\n      filters = build_filters(exclude, min_size)\n      result = await scan_directory_async(..., filters=filters)\n      if json:\n          typer.echo(orjson.dumps(result.to_dict()).decode())\n      else:\n          render_rich_tables(result)\n• Ensure --no-logo and --verbose modes interoperate with JSON output by gating formatting via context manager.",
        "testStrategy": "• Write Typer CLI tests using typer.testing.CliRunner to assert JSON structure validity and filter application.\n• Add snapshot tests for help text to prevent regressions.\n• Validate exclude/min-size parsing with unit tests, including edge cases (glob collisions, invalid sizes).\n• Add end-to-end tests invoking lazyscan scan --json on fixture directories to ensure stable schema for downstream tooling.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Plan Typer CLI migration",
            "description": "Review current CLI entrypoints and outline changes needed to migrate command definitions to Typer 0.12.3 while preserving existing Rich styling hooks.",
            "dependencies": [],
            "details": "Inventory current click-based command wiring, map arguments/options to Typer signatures, and define required context handling for --no-logo/--verbose.\n<info added on 2025-10-04T10:19:52.538Z>\nDocumented that the CLI already runs on Typer 0.12.3 with baseline --json, --exclude, and --min-size wiring, and recorded backend alignment work: scan_directory_async now accepts exclude_patterns, min_size_bytes, and max_depth while the synchronous wrapper forwards filtering parameters to preserve backward compatibility.\n</info added on 2025-10-04T10:19:52.538Z>",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement advanced filter validators",
            "description": "Add Typer option validators for --exclude globs, --min-size parsing with humanfriendly, and top-N selection logic.",
            "dependencies": [
              "22.1"
            ],
            "details": "Create reusable validation helpers, ensure error messages match cyberpunk tone, and integrate them into the Typer command options.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build orjson serialization layer",
            "description": "Implement serialization utilities using orjson>=3.9.15 for ScanResult and cleanup summaries with stable schemas.",
            "dependencies": [
              "22.1"
            ],
            "details": "Define to_dict methods or dataclass schema mappings, ensure ascii=False output, and document schema contracts for consumers.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate dual rendering pathways",
            "description": "Wire CLI execution flow to switch between JSON output and Rich-based rendering while honoring formatting flags.",
            "dependencies": [
              "22.1",
              "22.2",
              "22.3"
            ],
            "details": "Implement context manager gating for --no-logo/--verbose, ensure JSON mode bypasses Rich tables, and maintain themed output otherwise.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update help text and documentation",
            "description": "Refresh CLI help, usage strings, and README examples to reflect new options and JSON mode.",
            "dependencies": [
              "22.4"
            ],
            "details": "Add option descriptions, sample commands, and cross-reference cyberpunk UX notes in docs and --help output.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Expand automated CLI test coverage",
            "description": "Add unit, snapshot, and end-to-end tests to validate new CLI behavior, filters, and JSON output.",
            "dependencies": [
              "22.2",
              "22.3",
              "22.4",
              "22.5"
            ],
            "details": "Use typer.testing.CliRunner for CLI tests, assert JSON schemas, validate filter parsing edge cases, and capture help text snapshots.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 23,
        "title": "Expand Unity cache management capabilities",
        "description": "Enhance Unity integration with build directory handling, editor version detection, and package cache management for safer cleanups.",
        "details": "• Parse Unity Hub project manifests and Editor installation paths to detect per-project Unity version using packaging.version>=24.0 for comparisons.\n• Implement optional Build/ directory cleanup behind config flag unity.include_build_dir with confirm prompts and backup-first deletion via send2trash.\n• Add support for com.unity3d.PackageManager caches by resolving %APPDATA%/Unity/Cache or ~/Library/Unity/Cache using platformdirs.\n• Extend cache categorization metadata with rebuild cost, expected regen time, and safety flags for UI prompts.\n• Pseudo-code:\n  def collect_unity_targets(project):\n      paths = [\"Library\", \"Temp\", \"obj\", \"Logs\"]\n      if config.include_build_dir:\n          paths.append(\"Build\")\n      if config.manage_package_cache:\n          paths.append(package_cache_path(project.version))\n      return [CacheTarget(path=p, safety=SafetyLevel.WARN)]\n• Present aggregated size deltas in the interactive picker, highlighting high-impact directories.\n• Update documentation/help to explain rebuild implications and version-specific cache paths.",
        "testStrategy": "• Create unit tests with temp Unity project fixtures emulating various Hub schemas to ensure version parsing robustness.\n• Integration tests to simulate cleanup runs with dry-run mode, verifying that only flagged directories are touched.\n• Add regression tests to ensure backup archives are created and indexed before deletion.\n• Use hypothesis files to cover optional build dir toggles and config permutations.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Unity version detection workflow",
            "description": "Parse Unity Hub metadata to resolve per-project Unity Editor versions.",
            "dependencies": [],
            "details": "Build utilities that read Unity Hub project manifests and Editor installation directories, normalize detected versions using packaging.version>=24.0, and expose an API returning canonical version objects for downstream cache logic.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Extend Unity cache target collection",
            "description": "Add configurable discovery of build outputs and package caches for cleanup.",
            "dependencies": [
              "23.1"
            ],
            "details": "Update cache target enumeration to honor unity.include_build_dir and unity.manage_package_cache flags, append Build/ directories with confirmation hooks, resolve com.unity3d.PackageManager cache locations via platformdirs, and ensure send2trash is used for safe deletions.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Augment cache safety metadata",
            "description": "Enhance metadata to cover rebuild implications and safety classifications.",
            "dependencies": [
              "23.1",
              "23.2"
            ],
            "details": "Expand CacheTarget data to include rebuild cost, expected regeneration time, and safety flags, populating values for Library, Temp, obj, Logs, Build, and package cache directories so UI prompts can convey risk levels accurately.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update interactive picker with size deltas",
            "description": "Surface aggregated cache impacts and highlight high-value targets in UI.",
            "dependencies": [
              "23.2",
              "23.3"
            ],
            "details": "Modify the interactive picker to display size differentials per target set, emphasize high-impact directories using safety metadata, and verify that optional Build and package cache entries integrate into size summaries.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Refresh Unity cache management documentation",
            "description": "Document new cache handling behavior and rebuild considerations.",
            "dependencies": [
              "23.2",
              "23.3",
              "23.4"
            ],
            "details": "Revise help pages and configuration guides to explain per-version cache paths, optional Build directory cleanup, rebuild implications, safety warnings, and backup-first deletion flow.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop multi-platform test coverage",
            "description": "Create unit, integration, and regression tests for new Unity cache features.",
            "dependencies": [
              "23.1",
              "23.2",
              "23.3",
              "23.4"
            ],
            "details": "Author tests that mock diverse Unity Hub schemas, validate target collection under different configs, exercise dry-run cleanup flows across platforms, and ensure backup archives and safety metadata remain consistent over time.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 24,
        "title": "Extend Unreal Engine integration for advanced cache categories",
        "description": "Broaden Unreal project support with editor version detection, marketplace cache, shader cache, and blueprint cache handling.",
        "details": "• Parse .uproject metadata and Epic Launcher manifests to determine engine version; cross-reference %PROGRAMDATA%/Epic/UnrealEngineLauncher for installation paths.\n• Map DerivedDataCache, Intermediate, Saved/Logs, Saved/Crashes, Binaries, Marketplace assets (~/.cache/Epic/launcher) with safety classifications and rebuild hints.\n• Add CLI flags --unreal-include-binaries and --unreal-include-marketplace for optional cleanup, defaulting to safe caches only.\n• Implement size aggregation per category to inform UX and audit logs, leveraging pathlib.Path.glob for platform variations.\n• Pseudo-code:\n  def gather_unreal_targets(project):\n      targets = [\"DerivedDataCache\", \"Intermediate\", Path(\"Saved\")/\"Logs\"]\n      if opts.include_marketplace:\n          targets.append(marketplace_cache(project.version))\n      return build_cache_plan(targets, safety_map)\n• Update plugin hooks so Unreal modules register cleanup strategies via entry_points key \"lazyscan.unreal\" for future marketplace support.",
        "testStrategy": "• Unit tests with mocked manifest structures to ensure version extraction across Windows/macOS paths.\n• End-to-end dry-run tests verifying optional flags gate risky deletions.\n• Property-based tests validating that safety metadata blocks deletion when user confirmation not granted.\n• Regression tests ensuring audit logs capture category, size, and backup path for every deletion.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Unreal version and path discovery",
            "description": "Parse project metadata and launcher manifests to determine the Unreal Engine version and installation paths.",
            "dependencies": [],
            "details": "Read .uproject files and Epic Launcher manifests to resolve engine association, normalize platform-specific locations (Windows ProgramData and macOS equivalents), and surface canonical installation directories for downstream consumers.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Map Unreal cache categories with safety metadata",
            "description": "Define cache directories, rebuildability hints, and safety classifications for Unreal projects.",
            "dependencies": [
              "24.1"
            ],
            "details": "Enumerate DerivedDataCache, Intermediate, Saved/Logs, Saved/Crashes, Binaries, shader, blueprint, and marketplace cache paths; classify each with safety levels and rebuild guidance; ensure marketplace cache resolution leverages detected engine version.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add CLI flags for optional Unreal cache cleanup",
            "description": "Introduce --unreal-include-binaries and --unreal-include-marketplace flags to control risky deletions.",
            "dependencies": [
              "24.2"
            ],
            "details": "Extend CLI parsing to register new flags with clear help text, wire options into cleanup planning so risky categories are included only when requested, and update configuration defaults to preserve safe-only behavior.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement cache size aggregation and audit logging",
            "description": "Calculate per-category sizes and emit structured audit data for Unreal cleanup runs.",
            "dependencies": [
              "24.2"
            ],
            "details": "Use pathlib-based traversal to sum sizes for each cache category, aggregate totals for UX display and logging, and ensure audit entries capture inclusion source (default vs. flag-enabled) for compliance tracing.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Register Unreal cleanup strategies via plugin entry points",
            "description": "Expose Unreal cache handlers through the lazyscan.unreal entry point for modular integration.",
            "dependencies": [
              "24.2"
            ],
            "details": "Update plugin discovery to register Unreal modules under the lazyscan.unreal entry point, define strategy metadata for each cache category, and verify discovery integrates with existing plugin hooks for future marketplace extensions.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop targeted tests for Unreal integration",
            "description": "Create unit, property-based, and end-to-end tests covering new Unreal cache features.",
            "dependencies": [
              "24.1",
              "24.2",
              "24.3",
              "24.4",
              "24.5"
            ],
            "details": "Mock manifest structures to validate version parsing, add property-based tests ensuring safety metadata prevents unauthorized deletions, and run dry-run end-to-end scenarios verifying CLI flags and audit logs behave as expected.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 25,
        "title": "Implement multi-browser cache management",
        "description": "Add Firefox, Safari, Edge, and Brave cache discovery with profile-aware safety classifications and size breakdown reporting.",
        "details": "• Survey latest browser profile storage paths (2024-2025) and encode in platform-specific resolvers using browserhistory>=0.1.0 for helper patterns where available.\n• Implement profile discovery for:\n  – Firefox: profiles.ini parsing, caches2/entries and startupCache.\n  – Safari: ~/Library/Caches/com.apple.Safari, WebKitCache; ensure TCC permissions messaging on macOS Sonoma.\n  – Edge/Brave: leverage Chromium profile structure under AppData/Local/{Microsoft/Edge,BraveSoftware}/User Data.\n• Classify cache directories vs. persistent data using SAFE_TO_DELETE/UNSAFE lists, expanding to media/script/image breakdown by inspecting index DBs and file extensions.\n• Provide per-profile interactive selection with total size and breakdown, integrating with JSON output schema.\n• Pseudo-code:\n  def discover_firefox_profiles():\n      config = configparser.ConfigParser(); config.read(profiles_ini)\n      for section in sections:\n          yield BrowserProfile(name, path/\"cache2\"/\"entries\")\n• Ensure cross-platform permission handling (e.g., using pyobjc-framework for Safari flush where required) while defaulting to dry-run if elevated rights missing.",
        "testStrategy": "• Unit tests covering path resolution on macOS/Linux/Windows using fixture directories.\n• Integration tests running dry-run cleanups to confirm only safe directories scheduled for deletion.\n• Add schema validation tests for JSON breakdown output, ensuring categories (media, scripts, images) present when data available.\n• Manual QA checklist for Safari requiring notarized helper instructions, recorded in docs/tests/browser.md.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Research cross-platform browser cache locations",
            "description": "Compile up-to-date (2024-2025) cache and profile storage paths for Firefox, Safari, Edge, and Brave across Windows, macOS, and Linux.",
            "dependencies": [],
            "details": "Survey vendor documentation, release notes, and community resources to enumerate current cache directories and profile metadata files; validate findings against local fixtures or test installations; define resolver inputs using browserhistory>=0.1.0 patterns where applicable; document OS-specific edge cases for downstream implementation.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Firefox profile discovery resolver",
            "description": "Add Firefox-specific profile enumeration and cache discovery using profiles.ini and cache directory conventions.",
            "dependencies": [
              "25.1"
            ],
            "details": "Parse profiles.ini to identify profile roots, resolve caches2/entries and startupCache locations, detect default vs. custom profile paths, and expose results with profile metadata for safety classification; ensure support for Windows/macOS/Linux path variations derived from research.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Safari profile discovery with TCC awareness",
            "description": "Build Safari cache discovery on macOS, accounting for permissions prompts and alternative cache storage paths.",
            "dependencies": [
              "25.1"
            ],
            "details": "Resolve ~/Library/Caches/com.apple.Safari and WebKitCache variants, detect WebKit subdirectories per profile, surface required TCC permission messaging for macOS Sonoma+, and conditionally integrate pyobjc-based permission checks with dry-run fallback when access is denied.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Edge and Brave profile discovery",
            "description": "Leverage Chromium-based profile structures to enumerate Edge and Brave caches across supported platforms.",
            "dependencies": [
              "25.1"
            ],
            "details": "Traverse AppData/Local/{Microsoft/Edge,BraveSoftware}/User Data (and Linux/macOS equivalents), map Profiles to cache folders (GPUCache, Default/Cache, Code Cache, etc.), capture profile metadata, and expose normalized outputs for downstream classification and reporting.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Develop cache safety classification and breakdown logic",
            "description": "Classify discovered directories, differentiate safe vs. unsafe cache targets, and compute size breakdowns by content type.",
            "dependencies": [
              "25.2",
              "25.3",
              "25.4"
            ],
            "details": "Define SAFE_TO_DELETE/UNSAFE lists per browser, inspect IndexedDB/SQLite metadata and file extensions to attribute bytes to media/script/image categories, aggregate per-profile totals, and prepare structured data compatible with reporting schema.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Integrate interactive selection and JSON reporting updates",
            "description": "Enhance UI and JSON schema to present per-profile cache summaries with interactive selection and detailed breakdowns.",
            "dependencies": [
              "25.5"
            ],
            "details": "Update interactive prompts/workflows to list profiles with total cache size and category breakdowns, support dry-run indicators for permission-limited profiles, and align JSON output schema with new fields while maintaining backward compatibility.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Document cache management features and expand test coverage",
            "description": "Produce developer/user documentation and implement automated tests validating the new cache discovery pipeline.",
            "dependencies": [
              "25.2",
              "25.3",
              "25.4",
              "25.5",
              "25.6"
            ],
            "details": "Author documentation covering supported browsers, permission requirements, and safety guarantees; add unit tests for path resolution per OS, integration tests for dry-run scheduling, and schema validation tests ensuring media/script/image breakdown compliance; update changelog and usage guides accordingly.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 26,
        "title": "Add developer tool cache integrations",
        "description": "Introduce cache discovery and cleaning for VS Code, Xcode, Android Studio, and IntelliJ in line with developer-focused requirements.",
        "details": "• VS Code: target ~/.config/Code/User/workspaceStorage, extensions cache, language server tmp dirs; respect scoped settings via config.\n• Xcode: manage DerivedData, Archives, DeviceSupport, and CoreSimulator caches with options for device resets; warn about rebuild times.\n• Android Studio/IntelliJ: detect Gradle caches (~/.gradle/caches), build-cache, and IDE system dirs using JetBrains toolbox metadata; allow optional deletion of AVD images with explicit confirmation.\n• Implement modular discovery functions registered under apps/ to keep architecture pluggable; utilize dataclasses for CacheTarget definitions.\n• Pseudo-code:\n  def discover_vscode_caches():\n      base = platformdirs.user_cache_path(\"Code\")\n      return [CacheTarget(base/\"CachedData\", safety=SAFE)]\n• Update CLI `clean --app` command to accept new identifiers (vscode, xcode, androidstudio, intellij) with help descriptions.\n• Document expected reclaim sizes and rebuild implications in help output.",
        "testStrategy": "• Unit tests per integration mocking filesystem layout via pyfakefs to ensure accurate path detection.\n• Dry-run integration tests verifying selection prompts enumerate new apps and respect safety flags.\n• Regression tests ensuring backups created before deletion and logged with correct app identifiers.\n• Add performance tests to confirm large Gradle caches stream deletions without exhausting memory.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design VS Code cache discovery integration",
            "description": "Define cache discovery targets and safety levels for Visual Studio Code within the developer tooling integration.",
            "dependencies": [],
            "details": "Map workspaceStorage, extensions cache, and language server temp directories using platform-aware paths.\nCapture configuration-scoped exclusions so user overrides are respected.\nIdentify CacheTarget metadata including safety classification and estimated reclaim size.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Design Xcode cache discovery and reset coverage",
            "description": "Plan detection and management of Xcode cache directories, including reset-capable areas and communication of rebuild impacts.",
            "dependencies": [],
            "details": "Enumerate DerivedData, Archives, DeviceSupport, and CoreSimulator directories with sizing metadata.\nDetermine options for simulator/device resets and flag high-risk deletions.\nPrepare warning messaging for significant rebuild time implications.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Design Android Studio and IntelliJ cache discovery strategy",
            "description": "Outline cache discovery for Android Studio and IntelliJ ecosystems leveraging shared JetBrains infrastructure.",
            "dependencies": [],
            "details": "Identify Gradle caches (~/.gradle/caches), build-cache, and IDE system directories via JetBrains Toolbox metadata.\nSpecify handling for optional AVD image deletion requiring explicit confirmation.\nDefine CacheTarget dataclass fields for safety and size reporting.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement modular cache registration with optional deletion safeguards",
            "description": "Create pluggable discovery modules and integrate optional deletion confirmation flows across developer tools.",
            "dependencies": [
              "26.1",
              "26.2",
              "26.3"
            ],
            "details": "Register per-app discoverers under apps/ using unified interfaces and CacheTarget dataclasses.\nWire safety prompt handling for destructive actions, including AVD and simulator resets.\nEnsure configuration-driven enablement respects per-tool settings.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update CLI clean --app interface and rebuild documentation",
            "description": "Extend the CLI to support new app identifiers and document expected reclaim sizes along with rebuild considerations.",
            "dependencies": [
              "26.4"
            ],
            "details": "Add vscode, xcode, androidstudio, and intellij options to clean --app with descriptive help text.\nSurface warnings about rebuild times and optional deletions in CLI help output and user documentation.\nNote estimated reclaim sizes per tool in help and docs.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop pyfakefs and integration/regression test coverage",
            "description": "Implement automated tests ensuring accurate cache detection, prompt handling, and CLI integration for new developer tool support.",
            "dependencies": [
              "26.4",
              "26.5"
            ],
            "details": "Author pyfakefs-backed unit tests for each discoverer verifying path discovery and safety flags.\nAdd dry-run integration tests covering CLI selection prompts and configuration interactions.\nInclude regression tests validating backup logging before deletions.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 27,
        "title": "Broaden system cache cleanup coverage",
        "description": "Expand system-level cache management to cover Homebrew, npm/pip, Docker, Linux package managers, and Windows temp caches.",
        "details": "• Implement platform-aware resolvers:\n  – macOS: Homebrew cache (~/Library/Caches/Homebrew), npm cache (~/.npm), pip cache (~/.cache/pip), Docker (~/Library/Containers/com.docker.docker/Data/vms/0/data/Docker.raw) with warnings.\n  – Linux: ~/.cache, /var/cache/{apt,dnf,pacman}, journalctl --vacuum-size integration with subprocess, Docker overlay2 cleanup via docker CLI in dry-run first.\n  – Windows: %TEMP%, WinSxS Cleanup (DISM /Online /Cleanup-Image /StartComponentCleanup) with user confirmation, npm/pip in AppData.\n• Provide policy checks ensuring critical system directories are excluded unless explicitly allowed in config.\n• Pseudo-code:\n  def collect_system_caches(platform):\n      targets = base_targets[platform]\n      if config.security.require_confirmation:\n          targets = filter_requires_confirmation(targets)\n      return targets\n• Update JSON/CLI output to group results by platform component (package_manager, container, temp_files) for audit clarity.\n• Ensure operations integrate with backup-first deletion or command wrappers that log actions and capture tool output.",
        "testStrategy": "• Unit tests verifying resolver paths and size calculations per platform using fixture directories and monkeypatched env vars.\n• Integration tests running dry-run mode on CI containers (Ubuntu/macOS runners) to validate commands invoked correctly.\n• Mocked tests for Windows DISM commands to ensure proper warnings and no execution without flags.\n• Security regression tests confirming critical path protection blocks accidental deletions when config disallows elevated operations.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement platform-specific cache resolvers",
            "description": "Develop resolver modules for macOS, Linux, and Windows that identify cache directories for Homebrew, npm, pip, Docker, Linux package managers, and Windows temp locations, including path validation and platform nuance handling.",
            "dependencies": [],
            "details": "Cover the complete target list from the task description, include warnings for sensitive assets like Docker raw disks, and ensure resolvers return structured metadata suitable for later grouping.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build sensitive command wrappers and confirmation flows",
            "description": "Create wrappers for cleanup commands that enforce confirmation prompts, dry-run execution, and security policies before issuing deletion or system maintenance commands across platforms.",
            "dependencies": [
              "27.1"
            ],
            "details": "Support DISM, journalctl, docker CLI, and general filesystem deletions with dry-run support, user confirmation checks, and safe fallback behaviors when permissions or policies block execution.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Enforce configuration guardrails and exclusion policies",
            "description": "Implement configuration-driven safety checks preventing operations on critical directories unless explicitly authorized, integrating with the resolver output and confirmation logic.",
            "dependencies": [
              "27.2"
            ],
            "details": "Respect config.security.require_confirmation, enforce allowlists/denylists, and ensure guardrails are evaluated prior to any destructive action.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate backup-first deletion and action logging",
            "description": "Augment cleanup operations with backup mechanisms and logging that captures command output, execution status, and restoration metadata for auditability.",
            "dependencies": [
              "27.2",
              "27.3"
            ],
            "details": "Wrap destructive actions in backup routines, store logs centrally, and expose hooks for restoring data when needed.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Enhance reporting with platform component grouping",
            "description": "Update JSON and CLI outputs to categorize cache actions by package manager, container, and temp files, providing per-platform summaries and audit-friendly details.",
            "dependencies": [
              "27.1",
              "27.3"
            ],
            "details": "Align output schema with new resolver metadata, ensuring dry-run results and execution logs reflect grouped components and policy decisions.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Document platform behaviors and safety guidance",
            "description": "Produce detailed documentation describing cache coverage, command behaviors, confirmation requirements, and known risks for macOS, Linux, and Windows.",
            "dependencies": [
              "27.1",
              "27.2",
              "27.3",
              "27.4",
              "27.5"
            ],
            "details": "Include platform-specific caveats (e.g., Docker disk warnings, DISM prerequisites) and instructions for configuring guardrails and backups.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Conduct multi-platform dry-run and security regression testing",
            "description": "Design and execute tests validating dry-run behavior, command safety, and policy enforcement across supported platforms, including CI integration where applicable.",
            "dependencies": [
              "27.1",
              "27.2",
              "27.3",
              "27.4",
              "27.5",
              "27.6"
            ],
            "details": "Cover unit tests for resolver accuracy, mocked command execution for sensitive operations, and integration tests ensuring logging and reporting capture expected outputs.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 28,
        "title": "Upgrade security framework with encrypted audit logs",
        "description": "Enhance SecuritySentinel by encrypting audit logs, strengthening backup handling, and improving recovery workflows.",
        "details": "• Adopt cryptography>=41.0.7 (Fernet) for symmetric encryption of audit log payloads stored under platformdirs.user_data_dir(\"lazyscan\")/audits.\n• Generate/manage encryption keys via OS keychain (keyring>=24.3.0) with fallback to password-protected key files; document rotation procedure.\n• Extend audit schema to include hash digests (SHA-256) of backups, deletion decisions, and config snapshot for compliance readiness.\n• Implement recovery command updates to decrypt logs on demand, prompting user for unlock when key not accessible.\n• Pseudo-code:\n  class EncryptedAuditLogger:\n      def write(event):\n          token = fernet.encrypt(orjson.dumps(event))\n          audit_file.write(token + b\"\\n\")\n• Add safeguards ensuring encryption failures fail closed (abort delete) and surface actionable error messages in CLI/JSON output.",
        "testStrategy": "• Unit tests mocking keyring interactions to cover key creation, retrieval, and rotation scenarios.\n• Property-based tests ensuring encrypted logs decrypt to original payloads and tampering is detected.\n• Integration tests running full delete->recover flow verifying audit entries decrypt and reference backup archives.\n• Security tests using bandit/semgrep rules plus manual review to confirm no plaintext leaks and error handling aborts unsafe operations.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design encryption and key management strategy",
            "description": "Establish the technical approach for encrypting audit logs and managing symmetric keys.",
            "dependencies": [],
            "details": "Assess integration options for cryptography>=41.0.7 Fernet, map out data flow for encrypted audit storage, define how keys are generated, stored, and rotated using keyring>=24.3.0 with password-protected file fallback, and outline failure modes and unlock prompts.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update audit schema for compliance fields",
            "description": "Extend the audit record structure to support new integrity and compliance metadata.",
            "dependencies": [
              "28.1"
            ],
            "details": "Add SHA-256 digest fields for backups, document deletion decision logging, and capture configuration snapshots; ensure schema changes align with encryption design and serialization requirements.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement encrypted audit logger",
            "description": "Develop the logging component that writes encrypted audit events using the new schema.",
            "dependencies": [
              "28.1",
              "28.2"
            ],
            "details": "Create EncryptedAuditLogger that serializes events (orjson) and encrypts tokens with Fernet, handles key retrieval via keyring or fallback, manages storage under platformdirs user data audits directory, and ensures newline-delimited encrypted entries.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Enhance recovery workflows for encrypted audits",
            "description": "Update recovery commands to support decryption and key unlock interactions.",
            "dependencies": [
              "28.1",
              "28.3"
            ],
            "details": "Modify recovery CLI/commands to load encrypted audit entries, prompt for credentials when key access fails, decrypt logs on demand, and maintain compatibility with existing backup restore flows.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add fail-closed safeguards and error handling",
            "description": "Ensure encryption-related failures abort destructive actions and provide actionable feedback.",
            "dependencies": [
              "28.3"
            ],
            "details": "Implement guards that halt delete operations when encryption or key retrieval fails, propagate meaningful error messages through CLI/JSON outputs, and log incidents for diagnostics.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Document key rotation and recovery procedures",
            "description": "Produce documentation covering key lifecycle management and encrypted audit recovery steps.",
            "dependencies": [
              "28.1",
              "28.4"
            ],
            "details": "Draft operator guides for key creation, rotation, fallback key file usage, recovery workflows, and troubleshooting unlock issues, including compliance considerations.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Create comprehensive test coverage",
            "description": "Build unit, integration, and security-focused tests for the encrypted audit system.",
            "dependencies": [
              "28.2",
              "28.3",
              "28.4",
              "28.5"
            ],
            "details": "Implement mocked keyring unit tests, property-based encryption/decryption verification, failure-path tests for safeguards, and integration tests spanning delete-to-recover flow ensuring audit entries decrypt and integrity checks succeed.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 29,
        "title": "Introduce TOML-based configuration management",
        "description": "Replace legacy INI preferences with TOML-based configuration supporting per-application settings and themes.",
        "details": "• Utilize Python 3.11 tomllib for reading and tomli-w>=1.0.0 for writing TOML configs stored at platformdirs.user_config_path(\"lazyscan\")/config.toml.\n• Design schema aligning with PRD sample (general, scan, unity, security, theme sections) and add validation via pydantic>=2.5.3 models.\n• Implement migration script that converts existing preferences.ini on first run, preserving acknowledgments and user overrides.\n• Integrate configuration into CLI commands and integrations, enabling per-app toggles (e.g., unity.include_build_dir, security.backup_retention_days).\n• Pseudo-code:\n  class Config(BaseModel):\n      general: GeneralConfig\n      unity: UnityConfig\n  def load_config():\n      if legacy_ini.exists():\n          migrate_ini_to_toml()\n      data = tomllib.loads(config_path.read_text())\n      return Config.model_validate(data)\n• Update documentation and CLI `config` subcommand to support editing, validation feedback, and theme previews.",
        "testStrategy": "• Unit tests validating schema defaults, override precedence, and migration correctness using temp files.\n• Property-based tests generating random valid/invalid configs to ensure validation errors surface clearly.\n• Integration tests verifying CLI reads updated config and toggles influence cleanup behavior (e.g., include_build_dir true triggers extra targets).\n• Regression tests ensuring missing config files trigger creation with defaults and does not break headless automation.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define TOML configuration schema models",
            "description": "Design Pydantic models reflecting the PRD sections for the new TOML configuration.",
            "dependencies": [],
            "details": "Model sections for general, scan, unity, security, and theme settings with type hints, defaults, and documentation-ready field descriptions. Encode per-app toggles and theme attributes, ensuring compatibility with planned validation expectations.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement TOML load and save utilities",
            "description": "Create the configuration persistence pipeline using tomllib and tomli-w.",
            "dependencies": [
              "29.1"
            ],
            "details": "Build functions to resolve the config path via platformdirs, load TOML data into the Pydantic models, handle missing files by writing defaults, and persist updates atomically. Include error handling that surfaces validation issues gracefully.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop legacy INI migration tooling",
            "description": "Provide first-run migration from the legacy preferences.ini into the new TOML format.",
            "dependencies": [
              "29.1",
              "29.2"
            ],
            "details": "Detect existing INI files, map legacy keys into the new schema, merge with defaults, preserve acknowledgments and overrides, and write the resulting TOML using the persistence utilities. Add logging and idempotency safeguards.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate configuration into application logic",
            "description": "Update CLI commands and integrations to consume the new configuration toggles.",
            "dependencies": [
              "29.1",
              "29.2",
              "29.3"
            ],
            "details": "Refactor existing feature flags to read from the new models, honoring per-application settings like unity.include_build_dir and security.backup_retention_days. Ensure runtime components react to configuration changes without regressions.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Enhance CLI config tooling and documentation",
            "description": "Revise user-facing interfaces to manage the TOML configuration with validation feedback and theme previews.",
            "dependencies": [
              "29.1",
              "29.2",
              "29.3",
              "29.4"
            ],
            "details": "Extend the CLI `config` subcommand for listing, editing, and validating settings; add commands or prompts for theme previews. Update documentation to explain the new TOML file structure, migration notes, and usage examples.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Create validation and migration test suites",
            "description": "Implement automated tests covering schema validation, load/save behavior, and migration correctness.",
            "dependencies": [
              "29.1",
              "29.2",
              "29.3",
              "29.4",
              "29.5"
            ],
            "details": "Develop unit tests for model defaults and validation errors, property-based tests for config data, and regression tests verifying INI-to-TOML migration scenarios. Include integration tests ensuring CLI interactions respect configuration updates.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 30,
        "title": "Establish CI/CD pipeline with coverage and security gates",
        "description": "Set up GitHub Actions CI matrix for multi-platform, multi-Python testing with coverage, linting, and security scanning.",
        "details": "• Create .github/workflows/ci.yml running on push/PR with matrix: os=[ubuntu-latest, macos-latest, windows-latest], python=[3.8,3.9,3.10,3.11,3.12].\n• Configure steps: setup-python@v5, uv or pip caching, install deps, run pytest --cov=./lazyscan --cov-report=xml, upload to Codecov via codecov/codecov-action@v4.\n• Add lint stage running ruff>=0.1.9, black>=23.12, mypy, and bandit for security checks; ensure failure blocks merge.\n• Integrate pre-commit.ci or local pre-commit hooks to auto-format and enforce standards.\n• Provision nightly workflow for performance benchmarks using pytest-benchmark with trend detection (fail if regression >10%).\n• Document pipeline in CONTRIBUTING.md to guide contributors.",
        "testStrategy": "• Validate workflow locally with act where possible; run trial PR to ensure matrix executes successfully.\n• Add CI self-tests verifying coverage threshold (>=85%) enforced via pytest --cov-fail-under=85.\n• Monitor Codecov status checks and ensure they block merges when coverage drops.\n• Periodically run dependency review (github/codeql) and confirm alerts recorded; include manual checklist in release process.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Draft CI workflow structure for multi-platform matrix",
            "description": "Define the primary GitHub Actions workflow skeleton covering triggers and matrix parameters.",
            "dependencies": [],
            "details": "Create .github/workflows/ci.yml with push and pull_request triggers, establish a job matrix spanning os=[ubuntu-latest, macos-latest, windows-latest] and python=[3.8,3.9,3.10,3.11,3.12], and outline separate jobs or stages for tests and quality gates.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configure environment setup and dependency caching",
            "description": "Implement reusable steps for Python setup and package caching within the CI jobs.",
            "dependencies": [
              "30.1"
            ],
            "details": "Integrate actions/setup-python@v5 with the matrix, enable uv or pip caching keyed by OS/Python version, and ensure dependency installation commands are centralized via reusable run blocks or composite actions.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement test, coverage, lint, and security gates",
            "description": "Add execution steps enforcing test coverage thresholds and code quality/security checks.",
            "dependencies": [
              "30.1",
              "30.2"
            ],
            "details": "Run pytest with coverage for lazyscan enforcing --cov-fail-under=85, generate XML reports, upload via codecov/codecov-action@v4, and incorporate ruff, black, mypy, and bandit steps that must pass before merge; configure required status checks in workflow outputs.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Set up nightly performance benchmarking workflow",
            "description": "Create a scheduled GitHub Actions workflow dedicated to performance regression detection.",
            "dependencies": [
              "30.3"
            ],
            "details": "Author .github/workflows/nightly-benchmarks.yml triggered via cron, install benchmarking deps, execute pytest-benchmark suite, compare historical results, and fail the job when regression exceeds 10% with artifact/log retention for inspection.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Document pipeline and validate execution",
            "description": "Produce contributor guidance and confirm workflows operate as intended.",
            "dependencies": [
              "30.3",
              "30.4"
            ],
            "details": "Update CONTRIBUTING.md with CI requirements, local pre-commit usage, and coverage expectations; configure pre-commit.ci integration, dry-run workflows locally using act when feasible, and open a test PR to verify matrix, coverage gating, and Codecov status checks.",
            "status": "pending",
            "testStrategy": "",
            "parentId": "undefined"
          }
        ]
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-10-04T09:50:06.227Z",
      "taskCount": 10,
      "completedCount": 0,
      "tags": [
        "master"
      ],
      "created": "2025-10-04T09:50:55.965Z",
      "description": "Tasks for master context",
      "updated": "2025-10-04T11:43:17.767Z"
    }
  },
  "encrypted-audit": {
    "tasks": [
      {
        "id": 1,
        "title": "Design security.audit AES-256-GCM encryption schema",
        "description": "Finalize the security.audit AES-256-GCM encryption schema deliverable, ensuring backward compatibility, comprehensive key management integration, migration controls, and validated encryption/decryption logic are fully documented and approved.",
        "status": "in-progress",
        "dependencies": [],
        "priority": "medium",
        "details": "1. Document the inventory of the current security.audit data model, highlighting encryption-related fields, legacy schema elements, and key management references used as the basis for the redesign.\n2. Provide the expanded encryption schema incorporating AES-256-GCM, with finalized algorithm identifiers, key versioning metadata, rotation timestamps, and storage specifications for initialization vectors and authentication tags.\n3. Capture the approved backward-compatibility strategies (dual-read/double-write, feature flags, migration flags) that enable coexistence of legacy and new encrypted payloads.\n4. Detail the integrated key management approach, including external KMS references, key hierarchy, rotation policies, cache lifetimes, and failover handling as implemented in the design.\n5. Summarize the validation and error-handling rules for encrypt/decrypt operations, covering input validation, tag verification, logging, and audit trail requirements.\n6. Record data migration considerations such as batched re-encryption workflows, telemetry metrics, and rollback procedures validated during design reviews.\n7. Deliver the finalized architectural specification and schema documentation, including diagrams and configuration snippets approved by stakeholders.",
        "testStrategy": "- Verify the finalized schema document contains the complete set of fields, encryption parameters, and versioned metadata reflecting AES-256-GCM requirements.\n- Reference the completed design walkthrough outcomes with security and platform teams, confirming key management integration, rotation policies, and failure handling have been validated.\n- Review the executed sample encryption/decryption validations demonstrating legacy compatibility and adherence to AES-256-GCM expectations (IV length, tag length, key references).\n- Confirm documented migration flags, dual-read/double-write strategies, and rollback procedures align with backward compatibility decisions captured in the final design.\n- Ensure logging and audit requirements meet compliance expectations, incorporating the validated handling of encryption and validation failures.",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-10-04T06:20:51.615Z",
      "updated": "2025-10-04T06:21:03.766Z",
      "description": "Tag created on 4/10/2025"
    }
  }
}